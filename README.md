# arduino-temperature-streaming-demo

This project covers the process of deploying a simple architecture for real-time and batch processing of readings from a temperature sensor on arduino and with open source technologies from the Big Data ecosystem. The purpose of the solution is to exemplify the flow of data through the different tools, from its capture to its transformation and generation of Insights
## Introduction

**Arduino** is an open source platform focused on promoting and producing easy to use hardware and software components. Multiple Arduino boards are capable of reading different types of input signals, processing them, and generating some type of output signal. For this, it is necessary to develop and send a set of instructions (under a specific programming language) to the microcontroller of the board or component in use using the official Arduino IDE.

By using the Arduino board it is possible to take readings and interact with different sensors. A temperature and humidity sensor of the **DHT** family is used in this project. These types of sensors are quite slow and basic but serve their purpose. They are made up of two main components: a humidity sensor and a thermistor. They are also capable of performing analog to digital conversions and separating signals between temperature and humidity.

At the same time, depending on the Arduino board that is used, other types of components can be integrated to expand its functionalities. For example, regarding the sending of data over the internet, a chip of the **ESP2866** family can be used, which are low-cost alternatives that support the TCP / IP protocol and have both a small memory unit and its own microcontroller, which allows instructions to be loaded into the component as well.

Many may be the clients that can receive or consult the information generated by an Arduino board. One of the options most used by development communities is to use **Mosquitto**. Mosquitto is an open source implementation of a broker over the MQTT protocol (MQ Telemetry Transport) quite light. The Mosquitto project was developed by the Eclipse Foundation and includes libraries written in C and C ++, in addition to the mosquitto_pub and mosquitto_sub utilities for message posting and * topic * subscription.

However, Mosquitto lacks many functions that may be of great relevance for a specific project, such as offering facilities to store and check the persistence of topics. To do this, you can choose to redirect messages to a more robust solution like ** Apache Kafka **, which is an open source project written in Scala and developed by the Apache Software Foundation. Kafka implements a publication and subscription model for the intermediation of messages through channels or * topics *, offering more options at the level of security, storage, and manipulation of messages.

In order to redirect messages between one publication service and another, it is feasible to use the **Apache NiFi** tool, which allows to assemble data streams called *templates*, which are made up of (relatively) low instruction blocks. level called *processors*, which allow data to be captured and manipulated in real time, transformed and redirected to other means of persistence such as HDFS files, databases or other services.

It should be noted that it is beneficial to send the information to a means of persistence that allows batch processing of the information in a more traditional way. In the same order of ideas of open source tools, ** Apache Hive ** is presented as an attractive option. Hive is a relational datawarehouse that can be manipulated under an SQL-like language and has functionalities that make it stand out in clustered and / or distributed environments, facilitating the horizontal scaling of the datawarehouse, which is an important feature in projects where large volumes of information.

Much of this type of project requires the need for moderately simple, interactive and quick to implement explorations. Under this premise, consoles or interactive shells based on the creation of notebooks are very useful. **Apache Zeppelin** is an incubating project consisting of an implementation of the web idea / concept noteboook, which was first introduced by IPython. Zeppelin is focused on developing analytical and interactive data processes using technologies and languages ​​such as **Shell Script**, **SQL**, **Scala (Spark)**, **Hive**, **R** and else.
## Equipos usados

* **Arduino UNO R3 Clone - (USB Chip CH340) + Cable USB**
* **DHT11 humidity and temperature sensor**
* **WiFi Shield ESP 8266 ESP-01**
* **Protoboard MB-102**
* **Resistencia 1K (DHT)**
* **Resistencia 10K**
* **Cabling**

## Versiones de herramientas

* **Arduino IDE 1.8.5**
* **Hive 1.2.1**
* **Kafka 0.10.0**
* **Spark 1.6.2**
* **Zeppelin Notebook 0.6.0**
* **NiFi 1.2.0**

## Data flow

![Alt text](/images/architecture.png?raw=true "Architecture Diagram")

### 1 - Data generation from the temperature and humidity sensord.
* The code loaded on the Arduino platform takes readings through the temperature sensor every 3 seconds, capturing:
    * Percentage of humidity in the environment.
    * Temperature in degrees Celsius (° C)
    * Temperature in degrees Fahrenheit (° F)
* The Heat Index is calculated in Celsius and Fahrenheit, which determines how people perceive the temperature according to the humidity of the environment.
* A request is made to an external web service to determine the reading time according to a predefined time zone.

### 2 - Data publication to the MQTT server.
* Build the message or * payload * that will be sent to the MQTT server:
    * The payload will be built in JSON format.
    * Contains the data captured by the sensor, the calculated information, the date / time of the reading, the number of microseconds since the Arduino platform was turned on, and a unique identifier for the issuing client.
* Verifications of internet connection and MQTT server are carried out.
* The payload is published to the MQTT server.
    * The publication is made on a specific topic under a predefined username and password.
    * The MQTT server has a list of permissions where it defines which users can publish information on existing topics.

### 3, 4 y 5 - Captura de datos del servidor MQTT en tiempo real.
* El servicio Apache NiFi posee conjuntos organizados de instrucciones que orquestan el flujo de datos a medida que son captados:
   * NiFi se conecta o *suscribe* al tópico del Mosquitto y captura los mensajes que llegan en tiempo real.
   * NiFi complementa el mensaje recibido (cadena JSON) definiendo nuevos campos fuera de la cadena, relacionados a aspectos técnicos del mensaje y del servidor MQTT.
   * NiFi inserta la cadena JSON y los nuevos campos en el almacén de datos Hive.
   * NiFi publica el mensaje original en Kafka.
* Hive y Kafka guardan de forma persistente los datos:
   * Hive hace posible realizar procesamiento en batch de los datos históricos almacenados.
   * Kafka permite realizar procesamiento en tiempo real de los datos enviados por la palca Arduino.

### 6 y 7 - Procesamiento de datos.
* Zeppelin ejecuta bloques de código (en Scala y SQL):
   * Es posible consultar los datos en el almacén de datos.
   * Es posible suscribirse en tiempo real al tópico de Kafka para monitorear y procesar los datos recibidos en tiempo real bajo distintas ventanas de tiempo
* El código es ejecutado sobre el motor de procesamiento **Spark**.
* Los datos obtenidos en cada ventana de tiempo son transformados y almacenados en tablas en Hive.
* Se calcula la media de las temperaturas medidas en Fahrenheit sobre las ventanas de tiempo y se almacenan en Hive.

## Instalación

### Arduino IDE
El software necesario para cargar secuencias de instrucciones a la placa de Arduino se llama Arduino IDE y puede ser descargado desde la web [oficial de arduino](https://www.arduino.cc/en/Main/Software]). Puede ser descargado para Windows, Linux y Mac OS X.

### ESP8266
Para poder manipular el shield WiFi ESP8266 es necesario instalar componentes adicionales sobre el Arduino IDE. Esto permitirá configurar las opciones de compilación del código que se enviará al componente y utilizar los métodos y librerías para manipular las conexiones. 
El proceso de instalación se encuentra detallado en el [repositorio oficial de ESP8266 para Arduino](https://github.com/esp8266/Arduino.git), pero básicamente, la instalación puede llevarse a cabo mediante dos métodos:

#### Usando el Administrador de Placas de Arduino IDE
1. Iniciar el Arduino IDE y abrir la ventana de Preferencias bajo las pestaña Archivo.
2. Ingresar el valor `http://arduino.esp8266.com/stable/package_esp8266com_index.json` en el campo `Gestor de URLs Adicionales de Tarjetas`.
3. Abrir el *Gestor de Tarjetas* desde `Herramientas > Placa` e instalar la placa *esp8266*.

#### Usando Git
1. Dirigirse al directorio de instalación de Arduino.
2. Clonar el repositorio [esp8266/Arduino](https://github.com/esp8266/Arduino.git) en `hardware/esp8266com` :
```bash
cd hardware
mkdir esp8266com
cd esp8266com
git clone https://github.com/esp8266/Arduino.git esp8266
```
3. Descargar los archivos binarios con Python (2.7) :
```bash
cd esp8266/tools
python get.py
```
4. Reiniciar Arduino

### Librerías
Para manipular los sensores, realizar los procesos de publicación de información y entre otras funciones es necesario instalar librerías adicionales.

Para instalar una librería adicional es posible usar el *Gestor de Librerías del Arduino IDE* bajo la pestaña `Programas > Incluir librería`.

También es posible incluir librerías descargándolas de forma local en formato .ZIP y añadiéndolas desde la pestaña `Programas > Incluir librería > Añadir librería .ZIP`

Las adicionales usadas en este proyecto son:
* **Adafruit Unified Sensor 1.0.2**
* **DHT sensor library 1.3.0**
* **PubSubClient 2.6.0**
* **Time 1.5.0**
* **NTPClient 3.1.0**

## Montaje

Antes de presentar el diagrama del montaje de componentes, es necesario determinar cuáles son las entradas y salidas de cada componente y como se identifican dentro del diagrama.

### Diagrama Pinout ESP8266

* **TX** - Verde
* **GND** - Negro
* **CH_PD** - Naranja
* **GPIO2** - Azul
* **GPIO0** - Blanco
* **VCC** - Rojo
* **RX** - Amarillo

![Alt text](/images/esp8266_pinout.png?raw=true "ESP8266 Pinout Diagram")

### Diagrama Pinout DHT11

* **GND** - Blanco
* **Data** - Azul
* **VCC** - Naranja

![Alt text](/images/dht11_pinout.png?raw=true "ESP8266 Pinout Diagram")

### Diagrama Pinout del demo

La sección superior del protoboard se encuentra dedicada a los pines del módulo **ESP8266**, el cual se alimenta con voltaje de **3.3V** y usa una resistencia de **10k**. El flujo de voltaje al módulo WiFi es controlado por el **pin verde** conectado al protoboard en la última columna de la fila de carga positiva.

La sección inferior del protoboard está casi completamente dedicada al sensor de temperatura **DHT**. Este sensor trabaja con una voltaje de **5V** y una resistencia de **1k**.

![Alt text](images/demo_pinout_fm.png?raw=true "Demo Diagram Flash Mode")

**En este proyecto no se cargan instrucciones a la placa de Arduino, sino al módulo ESP8266**, ya que es éste quien enviará los datos y es quien se encargará de la manipulación y transformación de los mismos. 

Para cargar instrucciones al módulo WiFi es necesario que éste entre en Flash Mode al momento de inicio, lo cual se logra a través de la configuración de pines mostrada.

**Se recomienda que la placa de Arduino no tenga instrucciones cargadas al momentos de realizar la carga al módulo ESP8266.**

## Configuración

Debido a que la carga de las instrucciones no estará dirigida a la placa de arduino sino al shield WiFi, hay que seleccionar la placa ESP8266 y ajustar las opciones de compilación. Para ello seleccionamos la placa desde `Herramientas > Placa > Generic ESP8266 Module`.

La pestaña Herramientas tendrá nuevas opciones, las cuales se configurarán de la siguiente forma:
* **Flash Mode:** "DIO"
* **Flash Size:** "512K (64 SPIFFS)"
* **Debug port:** "Disabled"
* **Debug level:** "Ninguno"
* **Reset Method:** "ck"
* **Crystal Frequency:** "26 MHz"
* **Flash Frequency:** "40 MHz"
* **CPU Frequency:** "80 MHz"
* **Upload Speed:** "115200"
* **Programador:** "AVRISP mkII"

**Dependiendo del modelo del componente ESP8266 usado**, puede que sea necesario cambiar el parámetro **Upload Speed** a *9600*. Por defecto, la mayoría de los modelos trabajan bajo la velocidad de baudios *115200*.

## Sketch

Dentro de la comunidad de Arduino, el conjunto de instrucciones que se cargan en una placa son llamados *Sketch*. El Sketch que utilizaremos se encuentra en la carpeta `sketch` del repositorio.

Dentro del sketch es necesario editar la constantes declaradas al inicio con los datos pertinentes a nuestro ecosistema.

El sketch se encargará de: 
* Inicializar el monitor de serie del Arduino IDE, mediante el cual podremos visualizar las salidas del programa y monitorear el estado de ejecución.
* Inicializar el sensor de temperatura
* Establecer una conexión con la red WiFi definida.
* Consultar la fecha/hora a un servidor externo de acuerdo a la zona horaria definida.
* Definir el nombre del dispositivo emisor de datos (shield WiFi en nuestro caso)
* Establecer conexión con el servidor MQTT.
* Realizar lecturas del sensor de temperatura.
* Estructurar el payload en formato JSON.
* Enviar el payload al servidor MQTT.
* Realizar verificaciones de conexión y lecturas.
* Imprimir mensajes de control e información en el monitor de serie a la velocidad de baudios definida (en nuestro caso, 115200)

## Compilación, carga y ejecución

Es posible compilar el código antes de cargarlo a alguna placa haciendo clic en el botón *Verificar* de la interfaz del Arduino IDE.

Para cargar el código al módulo ESP8266, es necesario conectar la placa Arduino al ordenador mediante el puerto USB. De esta forma, será posible definir el puerto de comunicación con la placa bajo la pestaña `Herramientas > Puerto`, donde seleccionaremos el puerto disponible.

Podemos abrir el monitor de serie del Arduino IDE para verificar la ejecución del código cuando se realice la carga. Se recomiendan las siguientes opciones sobre el monitor para visualizar la información correcta:

* **Autoscroll**
* **Ambos NL & CR**
* **115200 baudio**

Una vez que el módulo ESP8266 reciba energía entrará en el **Flash Mode**, en el cual podremos cargarle las instrucciones del skecth.

Luego de que las instrucciones han sido cargadas, hay que conectar el **pin GPIO0 (blanco)** del módulo ESP8266 al voltaje bajo la resistencia. De esta forma, el módulo ESP8266 no entrará en el **Flash Mode** la próxima vez que la plataforma Arduino sea iniciada, permitiendo que ejecute el código cargado apenas reciba energía.

Aparte, el pin azul del sensor DHT transfiere las señales de salida, las cuales deben ser capturadas por el módulo WiFi a través del **pin GPIO2 (azul)**.

La configuración de pines quedaría de la siguiente forma:

![Alt text](images/demo_pinout_bm.png?raw=true "Demo Diagram Boot Mode")

En el monitor de serie podemos observar el proceso de conexión, captura y publicación de mensajes.

![Alt text](images/serial_monitor.png?raw=true "Serial monitor")

## Transferencia de publicaciones

**Nota:** Para información sobre despliegue, configuración, suscripción y publicación sobre Mosquitto y Kafka se recomienda consultar [éste repositorio](https://github.com/Gersaibot/mosquitto-kafka-integration) acerca de la integración entre ambos servicios.

Si nos suscribimos al tópico de Mosquitto podremos ver en tiempo real como los mensajes son publicados por la placa de Arduino.

En la carpeta `templates` se encuentra la plantilla de NiFi utilizada para capturar los datos de Mosquitto y enviarlos tanto a Kafka como a Hive. Cabe destacar que es necesario modificar los parámetros de conexión a cada uno de estos servicios como direcciones, tópicos, nombres de tablas, entre otros. 

![Alt text](images/nifi_template.png?raw=true "Demo Diagram Boot Mode")

Los mensajes capturados son publicados exactamente igual en Kafka y en Hive. En este último, se registran campos adicionales en la tabla, relacionados al servidor MQTT desde el cual se captura la información.

Una vez iniciada la plantilla, si nos suscribimos al tópico de Kafka al cual redirigimos los mensajes, podremos observar como los mensajes son publicados prácticamente al instante en que son recibidos en Mosquitto. En la siguiente imagen se puede apreciar la recepción de mensajes en el tópico de Mosquitto (izquierda) y el tópico de Kafka (derecha).

![Alt text](/images/mosquitto_kafka.gif?raw=true "Mosquitto and Kafka")

Por otro lado, si consultamos la tabla de Hive periódicamente, notaremos que el número de registros aumenta de acuerdo a los mensajes que son capturados por NiFi.

![Alt text](/images/hive_query.png?raw=true "Hive")

## Procesamiento en streaming

El notebook desarrollado con Scala se encuentra en la carpeta `notebooks` en formato JSON y puede ser importado en Zeppelin.

Las tablas creadas y utilizadas son las siguientes:

* **mqtt_message_temp**: Tabla temporal que almacenará los mensajes obtenidos en una ventana.
* **kafka_message**: Tabla que contendrá todos los datos obtenidos de cada una de las ventanas de consulta ejecutadas.
* **mean_fahrenheit_temp**: Tabla temporal que almacenará las medias calculadas de las temperaturas (° F) obtenidas en una ventana.
* **kafka_means_fahrenheit**: Tabla que contendrá todas las medias calculadas de cada una de las ventanas de consulta ejecutadas.
* **gen_test_data**: Tabla que contiene datos generados aleatoriamente para probar el modelo de clasificación Kmedias. Los datos pueden encontrarse en la carpeta `data/test_data`. Los datos fueron generados bajo las siguientes especificaciones:
   * **id**: Entero autoincremental (unidad) desde valor `1`.
   * **fecha**: String en formato `yyyy-MM-dd'T'HH:mm:ssZ` entre `2016-11-10` y `2018-10-31`.
   * **timestamp**: String de marca de tiempo en formato Unix desde `1478965467` hasta `1541592359`.
   * **fahrenheit**: String numérico aleatorio entre `15` y `125`.
   * **humedad**: String numérico aleatorio entre `25` y `85`.

El notebook contiene los siguientes 7 párrafos:

1. **Setup**
   * Importación de paquetes y librerías usadas en el resto de los párrafos.
   * Definición intervalo de segundos para el StreamingContext (batchIntervalSeconds).
   * Definición de duración de las ventanas de consulta (windowIntervalSeconds).
   * Defunción de parámetros de configuración para la conexión con Kafka bajo su antiguo API (kafkaConf).
2. **Captura de datos**
   * Verificaciones sobre contextos creados y/o creación de nuevos contextos.
   * Establecimiento de conexión con Kafka.
   * Ejecución de ventana de consulta sobre Kafka.
   * Calculo de la media de las temperaturas (°F) recibidas en la ventana.
   
![Alt text](/images/notebook_streaming.png?raw=true "Kafka messages in real time")

3. **Asociación de marcas de tiempo a medias**
   //probar notebook unificando cálculo de medias en un mismo párrafo <-
   * Asociación de la media calculada con marca de tiempo de generación de datos.
4. **Creación y entrenamiento de modelo Kmedias**
   * Transformación de datos históricos de ventanas como entrada al modelo.
   * Entrenamiento del modelo Kmedias en base a la temperatura (°F) y la humedad.
   * Almacenamiento de modelo en HDFS.
   * Calculo de la suma de los cuadrados dentro de cada clúster.
5. **Clasificación**
   * Carga de modelo previamente entrenado y almacenado en HDFS.
   * Clasificación de puntos obtenidos en la última ventana consultada.
   * Visualización de resultados.
6. **Clasificación - Datos aleatorios**
   * Carga de modelo previamente entrenado y almacenado en HDFS.
   * Clasificación de puntos aleatoriamente generados bajo rangos específicos.
   * Visualización de resultados.
![Alt text](/images/notebook_kmeans.png?raw=true "Kmeas prediction over random data")
7. **Seguimiento de datos**
   * Visualización de la evolución de la humedad y la temperatura (°C y °F) a lo largo del tiempo sobre los datos históricos de ventanas.
![Alt text](/images/notebook_kmeans.png?raw=true "Humidity and temperature overview over time")

## Mejoras

Este proyecto carece de las siguientes características que podrían aumentar el valor de la idea que se desea transmitir:
* Integración de placa Arduino con distintos tipos de sensores.
* Multiplicación de señales enviadas al módulo WiFi.
* Desarrollo de indicadores físicos de control y status sobre la ejecución de las instrucciones (LEDs, alertas, alarmas).
* Botón de activación/desactivación del **Flash Mode** del dispositivo WiFi.

## Conclusiones

Dentro de la arquitectura presentada los servicios de publicación, transferencia y almacenamiento de datos son agnósticos al formato en la cual los datos son enviados por la placa Arduino. Esta característica impulsa la idea de construir un servicio centralizado de distribución de mensajes, provenientes de distintos dispositivos emisores, hacia distintos clientes o servicios capaces de consumir estos datos.

Bajo esta premisa, las posibilidades de aplicabilidad de esta arquitectura son directamente proporcionales a la creatividad de implementación dispositivos emisores de información.

## Referencias
* [Documentación oficial de Arduino](https://www.arduino.cc/reference/en/)
* [Documentación oficial de Mosquitto](https://mosquitto.org/documentation/)
* [Documentación oficial de Apache NiFi](https://nifi.apache.org/docs.html)
* [Documentación oficial de Apache Hive](https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveDocumentation)
* [Documentación oficial de Apache Kafka](https://kafka.apache.org/documentation/)
* [Documentación oficial de Apache Zeppelin](https://zeppelin.apache.org/contribution/documentation.html)
* [Más proyectos sobre Arduino](https://create.arduino.cc/projecthub)
