# arduino-temperature-streaming-demo

This project covers the process of deploying a simple architecture for real-time and batch processing of readings from a temperature sensor on arduino and with open source technologies from the Big Data ecosystem. The purpose of the solution is to exemplify the flow of data through the different tools, from its capture to its transformation and generation of Insights
## Introduction

**Arduino** is an open source platform focused on promoting and producing easy to use hardware and software components. Multiple Arduino boards are capable of reading different types of input signals, processing them, and generating some type of output signal. For this, it is necessary to develop and send a set of instructions (under a specific programming language) to the microcontroller of the board or component in use using the official Arduino IDE.

By using the Arduino board it is possible to take readings and interact with different sensors. A temperature and humidity sensor of the **DHT** family is used in this project. These types of sensors are quite slow and basic but serve their purpose. They are made up of two main components: a humidity sensor and a thermistor. They are also capable of performing analog to digital conversions and separating signals between temperature and humidity.

At the same time, depending on the Arduino board that is used, other types of components can be integrated to expand its functionalities. For example, regarding the sending of data over the internet, a chip of the **ESP2866** family can be used, which are low-cost alternatives that support the TCP / IP protocol and have both a small memory unit and its own microcontroller, which allows instructions to be loaded into the component as well.

Many may be the clients that can receive or consult the information generated by an Arduino board. One of the options most used by development communities is to use **Mosquitto**. Mosquitto is an open source implementation of a broker over the MQTT protocol (MQ Telemetry Transport) quite light. The Mosquitto project was developed by the Eclipse Foundation and includes libraries written in C and C ++, in addition to the mosquitto_pub and mosquitto_sub utilities for message posting and * topic * subscription.

However, Mosquitto lacks many functions that may be of great relevance for a specific project, such as offering facilities to store and check the persistence of topics. To do this, you can choose to redirect messages to a more robust solution like ** Apache Kafka **, which is an open source project written in Scala and developed by the Apache Software Foundation. Kafka implements a publication and subscription model for the intermediation of messages through channels or * topics *, offering more options at the level of security, storage, and manipulation of messages.

In order to redirect messages between one publication service and another, it is feasible to use the **Apache NiFi** tool, which allows to assemble data streams called *templates*, which are made up of (relatively) low instruction blocks. level called *processors*, which allow data to be captured and manipulated in real time, transformed and redirected to other means of persistence such as HDFS files, databases or other services.

It should be noted that it is beneficial to send the information to a means of persistence that allows batch processing of the information in a more traditional way. In the same order of ideas of open source tools, ** Apache Hive ** is presented as an attractive option. Hive is a relational datawarehouse that can be manipulated under an SQL-like language and has functionalities that make it stand out in clustered and / or distributed environments, facilitating the horizontal scaling of the datawarehouse, which is an important feature in projects where large volumes of information.

Much of this type of project requires the need for moderately simple, interactive and quick to implement explorations. Under this premise, consoles or interactive shells based on the creation of notebooks are very useful. **Apache Zeppelin** is an incubating project consisting of an implementation of the web idea / concept noteboook, which was first introduced by IPython. Zeppelin is focused on developing analytical and interactive data processes using technologies and languages ​​such as **Shell Script**, **SQL**, **Scala (Spark)**, **Hive**, **R** and else.
## Used equipment

* **Arduino UNO R3 Clone - (USB Chip CH340) + Cable USB**
* **DHT11 humidity and temperature sensor**
* **WiFi Shield ESP 8266 ESP-01**
* **Protoboard MB-102**
* **Resistencia 1K (DHT)**
* **Resistencia 10K**
* **Cabling**

## Tool versions

* **Arduino IDE 1.8.5**
* **Hive 1.2.1**
* **Kafka 0.10.0**
* **Spark 1.6.2**
* **Zeppelin Notebook 0.6.0**
* **NiFi 1.2.0**

## Data flow

![Alt text](/images/architecture.png?raw=true "Architecture Diagram")

### 1 - Data generation from the temperature and humidity sensord.
* The code loaded on the Arduino platform takes readings through the temperature sensor every 3 seconds, capturing:
    * Percentage of humidity in the environment.
    * Temperature in degrees Celsius (° C)
    * Temperature in degrees Fahrenheit (° F)
* The Heat Index is calculated in Celsius and Fahrenheit, which determines how people perceive the temperature according to the humidity of the environment.
* A request is made to an external web service to determine the reading time according to a predefined time zone.

### 2 - Data publication to the MQTT server.
* Build the message or * payload * that will be sent to the MQTT server:
    * The payload will be built in JSON format.
    * Contains the data captured by the sensor, the calculated information, the date / time of the reading, the number of microseconds since the Arduino platform was turned on, and a unique identifier for the issuing client.
* Verifications of internet connection and MQTT server are carried out.
* The payload is published to the MQTT server.
    * The publication is made on a specific topic under a predefined username and password.
    * The MQTT server has a list of permissions where it defines which users can publish information on existing topics.

### 3, 4 and 5 - Capture data from the MQTT server in real time.
* The Apache NiFi service has organized sets of instructions that orchestrate the data flow as it is captured:
   * NiFi connects or *subscribes* to the Mosquitto topic and captures incoming messages in real time.
   * NiFi complements the received message (JSON string) by defining new fields outside the string, related to technical aspects of the message and the MQTT server.
   * NiFi inserts the JSON string and the new fields into the Hive data store.
   * NiFi publishes the original message on Kafka.
* Hive and Kafka persistently save the data:
   * Hive makes it possible to perform batch processing of stored historical data.
   * Kafka allows real-time processing of the data sent by the Arduino board.

### 6 and 7 - Data processing.
* Zeppelin executes blocks of code (in Scala and SQL):
   * It is possible to consult the data in the data warehouse.
   * It is possible to subscribe in real time to the Kafka topic to monitor and process the data received in real time under different time windows
* The code is executed on the **Spark** processing engine.
* The data obtained in each time window are transformed and stored in tables in Hive.
* The mean temperatures measured in Fahrenheit are calculated over time windows and stored in Hive.

## Installation

### Arduino IDE
The software required to upload instruction sequences to the Arduino board is called the Arduino IDE and can be downloaded from the [arduino official](https://www.arduino.cc/en/Main/Software]) website. It can be downloaded for Windows, Linux and Mac OS X.

### ESP8266
In order to manipulate the ESP8266 WiFi shield it is necessary to install additional components on the Arduino IDE. This will allow you to configure the compilation options of the code that will be sent to the component and use the methods and libraries to manipulate the connections.
The installation process is detailed in the [official ESP8266 repository for Arduino] (https://github.com/esp8266/Arduino.git), but basically, the installation can be carried out using two methods:

#### Using the Arduino IDE Board Manager
1. Start the Arduino IDE and open the Preferences window under the File tab.
2. Enter the value `http://arduino.esp8266.com/stable/package_esp8266com_index.json` in the field `Additional Card URL Manager`.
3. Open the *Card Manager* from `Tools> Board` and install the board *esp8266*.

#### Using Git
1. Go to the Arduino installation directory.
2. Clone the [esp8266/Arduino] repository (https://github.com/esp8266/Arduino.git) in `hardware/esp8266com`:
```bash
cd hardware
mkdir esp8266com
cd esp8266com
git clone https://github.com/esp8266/Arduino.git esp8266
```
3. Download the binary files with Python (2.7):
```bash
cd esp8266/tools
python get.py
```
4. Restart Arduino

### Libraries
To manipulate the sensors, carry out the information publication processes and among other functions, it is necessary to install additional libraries.

To install an additional library it is possible to use the * Arduino IDE Library Manager * under the `Programs> Include library` tab.

It is also possible to include libraries by downloading them locally in .ZIP format and adding them from the `Programs> Include library> Add .ZIP library` tab.

The additional ones used in this project are:
* **Adafruit Unified Sensor 1.0.2**
* **DHT sensor library 1.3.0**
* **PubSubClient 2.6.0**
* **Time 1.5.0**
* **NTPClient 3.1.0**

## Assembly

Before presenting the component assembly diagram, it is necessary to determine what the inputs and outputs of each component are and how they are identified within the diagram.

### Pinout Diagram ESP8266

* **TX** - Green
* **GND** - Black
* **CH_PD** - Orange
* **GPIO2** - Blue
* **GPIO0** - White
* **VCC** - Red
* **RX** - Yellow

![Alt text](/images/esp8266_pinout.png?raw=true "ESP8266 Pinout Diagram")

### Diagrama Pinout DHT11

* **GND** - While
* **Data** - Blue
* **VCC** - Orange

![Alt text](/images/dht11_pinout.png?raw=true "ESP8266 Pinout Diagram")

### Demo Pinout Diagram

The top section of the breadboard is dedicated to the pins of the **ESP8266** module, which is powered by ** 3.3V ** voltage and uses a **10k** resistor. The voltage flow to the WiFi module is controlled by the **green pin** connected to the breadboard in the last column of the positive charge row.

The lower section of the breadboard is almost entirely dedicated to the **DHT** temperature sensor. This sensor works with a voltage of **5V** and a resistance of **1k**.

![Alt text](images/demo_pinout_fm.png?raw=true "Demo Diagram Flash Mode")

**In this project, instructions are not loaded to the Arduino board, but to the ESP8266 module**, since it is the latter who will send the data and who will be in charge of manipulating and transforming them.

To upload instructions to the WiFi module, it is necessary to enter the Flash Mode at the start time, which is achieved through the pin configuration shown.

**It is recommended that the Arduino board does not have instructions loaded at the time of loading the ESP8266 module.**

## Setting

Since the loading of the instructions will not be directed to the arduino board but to the WiFi shield, it is necessary to select the ESP8266 board and adjust the compilation options. For this we select the board from `Tools> Board> Generic ESP8266 Module`.

The Tools tab will have new options, which will be configured as follows:
* **Flash Mode:** "DIO"
* **Flash Size:** "512K (64 SPIFFS)"
* **Debug port:** "Disabled"
* **Debug level:** "None"
* **Reset Method:** "ck"
* **Crystal Frequency:** "26 MHz"
* **Flash Frequency:** "40 MHz"
* **CPU Frequency:** "80 MHz"
* **Upload Speed:** "115200"
* **Developer:** "AVRISP mkII"

** Depending on the model of the ESP8266 component used **, it may be necessary to change the parameter** Upload Speed ​​** to *9600*. By default, most models work at the baud rate *115200*.

## Sketch

Within the Arduino community, the set of instructions that are loaded onto a board are called *Sketch*. The Sketch we will use is located in the `sketch` folder of the repository.

Within the sketch it is necessary to edit the constants declared at the beginning with the data relevant to our ecosystem.

The sketch will be in charge of:
* Initialize the serial monitor of the Arduino IDE, through which we can view the program outputs and monitor the execution status.
* Initialize temperature sensor
* Establish a connection with the defined WiFi network.
* Check the date / time with an external server according to the defined time zone.
* Define the name of the data emitting device (WiFi shield in our case)
* Establish connection to the MQTT server.
* Take readings from the temperature sensor.
* Structure the payload in JSON format.
* Send the payload to the MQTT server.
* Perform connection checks and readings.
* Print control messages and information on the serial monitor at the defined baud rate (in our case, 115200)

## Compilation, loading and execution

It is possible to compile the code before uploading it to any board by clicking the *Verify* button on the Arduino IDE interface.

To upload the code to the ESP8266 module, it is necessary to connect the Arduino board to the computer through the USB port. In this way, it will be possible to define the communication port with the board under the `Tools> Port` tab, where we will select the available port.

We can open the serial monitor of the Arduino IDE to verify the execution of the code when loading. The following monitor options are recommended to display the correct information:

* **Autoscroll**
* **Both NL & CR**
* **115200 baud**

Once the ESP8266 module receives power, it will enter the ** Flash Mode **, in which we can load the skecth instructions.

After the instructions have been loaded, connect the ** GPIO0 pin (white) ** of the ESP8266 module to the voltage under resistance. In this way, the ESP8266 module will not enter ** Flash Mode ** the next time the Arduino platform is started, allowing it to run the loaded code as soon as it receives power.

Besides, the blue pin of the DHT sensor transfers the output signals, which must be captured by the WiFi module through the **GPIO2 pin (blue)**.

The pin configuration would be as follows:

![Alt text](images/demo_pinout_bm.png?raw=true "Demo Diagram Boot Mode")

In the serial monitor we can observe the process of connection, capture and publication of messages.

![Alt text](images/serial_monitor.png?raw=true "Serial monitor")

## Transfer of publications

** Note: ** For information on deployment, configuration, subscription and publication on Mosquitto and Kafka it is recommended to consult [this repository] (https://github.com/Gersaibot/mosquitto-kafka-integration) about the integration between both services.

If we subscribe to the Mosquitto topic we will be able to see in real time how the messages are published by the Arduino board.

In the `templates` folder you will find the NiFi template used to capture the Mosquitto data and send it to both Kafka and Hive. It should be noted that it is necessary to modify the connection parameters to each of these services such as addresses, topics, table names, among others.

![Alt text](images/nifi_template.png?raw=true "Demo Diagram Boot Mode")

The captured messages are published exactly the same in Kafka and in Hive. In the latter, additional fields are recorded in the table, related to the MQTT server from which the information is captured.

Once the template is started, if we subscribe to the Kafka topic to which we redirect the messages, we will be able to see how the messages are published almost instantly when they are received in Mosquitto. In the following image you can see the reception of messages on the Mosquitto topic (left) and the Kafka topic (right).

![Alt text](/images/mosquitto_kafka.gif?raw=true "Mosquitto and Kafka")

On the other hand, if we consult the Hive table periodically, we will notice that the number of records increases according to the messages that are captured by NiFi.

![Alt text](/images/hive_query.png?raw=true "Hive")

## Streaming processing

The notebook developed with Scala is located in the `notebooks` folder in JSON format and can be imported into Zeppelin.

The tables created and used are as follows:

* **mqtt_message_temp**: Temporary table that will store the messages obtained in a window.
* **kafka_message**: Table that will contain all the data obtained from each of the query windows executed.
* **mean_fahrenheit_temp**: Temporary table that will store the calculated averages of the temperatures (° F) obtained in a window.
* **kafka_means_fahrenheit**: Table that will contain all the calculated means of each one of the executed query windows.
* **gen_test_data**: Table containing randomly generated data to test the Kmedias classification model. The data can be found in the `data / test_data` folder. The data was generated under the following specifications:
   * **id**: Autoincremental integer (unit) from value `1`.
   * **date**: String in format `yyyy-MM-dd'T'HH: mm: ssZ` between` 2016-11-10` and `2018-10-31`.
   * **timestamp**: Timestamp string in Unix format from `1478965467` to` 1541592359`.
   * **fahrenheit**: Random numeric string between `15` and` 125`.
   * **humidity**: Random numeric string between `25` and` 85`.

The notebook contains the following 7 paragraphs:

1. **Setup**
   * Import of packages and libraries used in the rest of the paragraphs.
   * Definition second interval for the StreamingContext (batchIntervalSeconds).
   * Definition of duration of query windows (windowIntervalSeconds).
   * Death of configuration parameters for the connection to Kafka under its old API (kafkaConf).
2. **Data capture**
   * Verifications on created contexts and/or creation of new contexts.
   * Establishment of connection with Kafka.
   * Execution of query window on Kafka.
   * Calculation of the average of the temperatures (° F) received in the window.
   
![Alt text](/images/notebook_streaming.png?raw=true "Kafka messages in real time")

3. **Half Timestamp Association**
   // test notebook unifying calculation of means in the same paragraph <-
   * Association of the calculated mean with time stamp of data generation.
4. **Creation and training of Kmedias model**
   * Transformation of historical window data as input to the model.
   * Kmedias model training based on temperature (° F) and humidity.
   * Storage of model in HDFS.
   * Calculation of the sum of squares within each cluster.
5. **Classification**
   * Upload of previously trained model stored in HDFS.
   * Classification of points obtained in the last window consulted.
   * Visualization of results.
6. **Ranking - Random Data**
   * Upload of previously trained model stored in HDFS.
   * Classification of randomly generated points under specific ranges.
   * Visualization of results.
![Alt text](/images/notebook_kmeans.png?raw=true "Kmeas prediction over random data")
7. ** Data tracking **
   * Visualization of the evolution of humidity and temperature (° C and ° F) over time on historical window data.
![Alt text](/images/notebook_kmeans.png?raw=true "Humidity and temperature overview over time")

## Improvements

This project lacks the following characteristics that could increase the value of the idea that you want to convey:
* Arduino board integration with different types of sensors.
* Multiplication of signals sent to the WiFi module.
* Development of physical indicators of control and status on the execution of instructions (LEDs, alerts, alarms).
* Button to enable/disable the **Flash Mode** of the WiFi device.

## Conclusions

Within the presented architecture, the services of publication, transfer and storage of data are agnostic to the format in which the data is sent by the Arduino board. This feature drives the idea of ​​building a centralized message distribution service, from different sending devices, to different clients or services capable of consuming this data.

Under this premise, the applicability possibilities of this architecture are directly proportional to the creativity of implementing information-emitting devices.

## References
* [Official Arduino documentation] (https://www.arduino.cc/reference/en/)
* [Mosquitto official documentation] (https://mosquitto.org/documentation/)
* [Apache NiFi official documentation] (https://nifi.apache.org/docs.html)
* [Apache Hive Official Documentation] (https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveDocumentation)
* [Apache Kafka official documentation] (https://kafka.apache.org/documentation/)
* [Apache Zeppelin official documentation] (https://zeppelin.apache.org/contribution/documentation.html)
* [More projects on Arduino] (https://create.arduino.cc/projecthub)
